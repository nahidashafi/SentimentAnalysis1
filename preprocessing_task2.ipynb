{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import re as regex\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, \n",
    "from time import time\n",
    "import gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Initialize():\n",
    "    data = []\n",
    "    processed_data = []\n",
    "    wordlist = []\n",
    "\n",
    "    data_model = None\n",
    "    data_labels = None\n",
    "    is_testing = False\n",
    "    \n",
    "    def initialize(self, csv_file, is_testing_set=False, from_cached=None):\n",
    "        if from_cached is not None:\n",
    "            self.data_model = pd.read_csv(from_cached)\n",
    "            return\n",
    "\n",
    "        self.is_testing = is_testing_set\n",
    "\n",
    "        if not is_testing_set:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"emotion\", \"text\"])\n",
    "            self.data = self.data[self.data[\"emotion\"].isin([\"positive\", \"negative\", \"neutral\"])]\n",
    "        else:\n",
    "            self.data = pd.read_csv(csv_file, header=0, names=[\"id\", \"text\"],dtype={\"id\":\"int64\",\"text\":\"str\"},nrows=4000)\n",
    "            not_null_text = 1 ^ pd.isnull(self.data[\"text\"])\n",
    "            not_null_id = 1 ^ pd.isnull(self.data[\"id\"])\n",
    "            self.data = self.data.loc[not_null_id & not_null_text, :]\n",
    "\n",
    "        self.processed_data = self.data\n",
    "        self.wordlist = []\n",
    "        self.data_model = None\n",
    "        self.data_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635769805279248384</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>IOS 9 App Transport Security. Mm need to check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mar if you have an iOS device, you should down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>@jimmie_vanagon my phone does not run on lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not sure how to start your publication on iOS?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>635769805279248384</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>IOS 9 App Transport Security. Mm need to check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mar if you have an iOS device, you should down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>@jimmie_vanagon my phone does not run on lates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not sure how to start your publication on iOS?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Initialize()\n",
    "data.initialize(\"kaggletrain.csv\")\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data distribution\n",
    "First thing that can be done as soon as the data is loaded is to see the data distribution. The training set had the following distribution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"24b2701e-1d89-40fe-b658-815261ee715e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"24b2701e-1d89-40fe-b658-815261ee715e\", [{\"type\": \"bar\", \"y\": [956, 2125, 2888], \"x\": [\"negative\", \"neutral\", \"positive\"]}], {\"title\": \"Sentiment type distribution in training set\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.processed_data\n",
    "neg = len(df[df[\"emotion\"] == \"negative\"])\n",
    "pos = len(df[df[\"emotion\"] == \"positive\"])\n",
    "neu = len(df[df[\"emotion\"] == \"neutral\"])\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=[\"negative\",\"neutral\",\"positive\"],\n",
    "        y=[neg, neu, pos],\n",
    ")]\n",
    "plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Sentiment type distribution in training set\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing steps\n",
    "The target of the following preprocessing is to create a **Bag-of-Words** representation of the data. The steps will execute as follows:\n",
    "1. Cleansing\n",
    "<ol style=\"list-style-type:decimal\"><li>Remove URLs</li>\n",
    "<li>Remove usernames (mentions)</li>\n",
    "<li>Remove tweets with *Not Available* text</li>\n",
    "<li>Remove special characters</li>\n",
    "<li>Remove numbers</li></ol>\n",
    "1. Text processing\n",
    "<ol style=\"list-style-type:decimal\">\n",
    "<li>Tokenize</li>\n",
    "<li>Transform to lowercase</li>\n",
    "<li>Stem</li></ol>\n",
    "1. Build word list for Bag-of-Words\n",
    "\n",
    "### Cleansing\n",
    "For the purpose of cleansing, i created ```TwitterCleanup``` . It consists methods allowing to execute all of the tasks show in the list above. Most of those is done using regular expressions.\n",
    "The class exposes it's interface through ```iterate()``` method - it yields every cleanup method in proper order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterCleanuper:\n",
    "    def iterate(self):\n",
    "        for cleanup_method in [self.remove_urls,\n",
    "                               self.remove_usernames,\n",
    "                               self.remove_na,\n",
    "                               self.remove_special_chars,\n",
    "                               self.remove_numbers]:\n",
    "            yield cleanup_method\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_by_regex(tweets, regexp):\n",
    "        tweets.loc[:, \"text\"].replace(regexp, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_urls(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"http.?://[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_na(self, tweets):\n",
    "        return tweets[tweets[\"text\"] != \"Not Available\"]\n",
    "\n",
    "    def remove_special_chars(self, tweets):  # it unrolls the hashtags to normal words\n",
    "        for remove in map(lambda r: regex.compile(regex.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
    "                                                                     \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
    "                                                                     \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
    "                                                                     \"!\", \"?\", \".\", \"'\",\n",
    "                                                                     \"--\", \"---\", \"#\"]):\n",
    "            tweets.loc[:, \"text\"].replace(remove, \"\", inplace=True)\n",
    "        return tweets\n",
    "\n",
    "    def remove_usernames(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"@[^\\s]+[\\s]?\"))\n",
    "\n",
    "    def remove_numbers(self, tweets):\n",
    "        return TwitterCleanuper.remove_by_regex(tweets, regex.compile(r\"\\s?[0-9]+\\.?[0-9]*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded tweets can be now cleaned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Cleansing(TwitterData_Initialize):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def cleanup(self, cleanuper):\n",
    "        t = self.processed_data\n",
    "        for cleanup_method in cleanuper.iterate():\n",
    "            if not self.is_testing:\n",
    "                t = cleanup_method(t)\n",
    "            else:\n",
    "                if cleanup_method.__name__ != \"remove_na\":\n",
    "                    t = cleanup_method(t)\n",
    "\n",
    "        self.processed_data = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# My first_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3443: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>IOS App Transport Security Mm need to check if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Mar if you have an iOS device you should downl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>my phone does not run on latest IOS which may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>Not sure how to start your publication on iOS ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>636176272947744772</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Two Dollar Tuesday is here with Forklift Quick...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   emotion  \\\n",
       "1  635930169241374720   neutral   \n",
       "2  635950258682523648   neutral   \n",
       "3  636030803433009153  negative   \n",
       "4  636100906224848896  positive   \n",
       "5  636176272947744772   neutral   \n",
       "\n",
       "                                                text  \n",
       "1  IOS App Transport Security Mm need to check if...  \n",
       "2  Mar if you have an iOS device you should downl...  \n",
       "3  my phone does not run on latest IOS which may ...  \n",
       "4  Not sure how to start your publication on iOS ...  \n",
       "5  Two Dollar Tuesday is here with Forklift Quick...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_Cleansing(data)\n",
    "data.cleanup(TwitterCleanuper())\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization & stemming\n",
    "For the text processing, ```nltk``` library is used. First, the tweets are tokenized using ```nlkt.word_tokenize``` and then, stemming is done using **PorterStemmer** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_TokenStem(TwitterData_Cleansing):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    def stem(self, stemmer=nltk.PorterStemmer()):\n",
    "        def stem_and_join(row):\n",
    "            row[\"text\"] = list(map(lambda str: stemmer.stem(str.lower()), row[\"text\"]))\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(stem_and_join, axis=1)\n",
    "\n",
    "    def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"text\"] = tokenizer(row[\"text\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"text\"]\n",
    "            return row\n",
    "\n",
    "        self.processed_data = self.processed_data.apply(tokenize_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>635930169241374720</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[io, app, transport, secur, mm, need, to, chec...</td>\n",
       "      <td>[IOS, App, Transport, Security, Mm, need, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635950258682523648</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[mar, if, you, have, an, io, devic, you, shoul...</td>\n",
       "      <td>[Mar, if, you, have, an, iOS, device, you, sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>636030803433009153</td>\n",
       "      <td>negative</td>\n",
       "      <td>[my, phone, doe, not, run, on, latest, io, whi...</td>\n",
       "      <td>[my, phone, does, not, run, on, latest, IOS, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>636100906224848896</td>\n",
       "      <td>positive</td>\n",
       "      <td>[not, sure, how, to, start, your, public, on, ...</td>\n",
       "      <td>[Not, sure, how, to, start, your, publication,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>636176272947744772</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[two, dollar, tuesday, is, here, with, forklif...</td>\n",
       "      <td>[Two, Dollar, Tuesday, is, here, with, Forklif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id   emotion  \\\n",
       "1  635930169241374720   neutral   \n",
       "2  635950258682523648   neutral   \n",
       "3  636030803433009153  negative   \n",
       "4  636100906224848896  positive   \n",
       "5  636176272947744772   neutral   \n",
       "\n",
       "                                                text  \\\n",
       "1  [io, app, transport, secur, mm, need, to, chec...   \n",
       "2  [mar, if, you, have, an, io, devic, you, shoul...   \n",
       "3  [my, phone, doe, not, run, on, latest, io, whi...   \n",
       "4  [not, sure, how, to, start, your, public, on, ...   \n",
       "5  [two, dollar, tuesday, is, here, with, forklif...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "1  [IOS, App, Transport, Security, Mm, need, to, ...  \n",
       "2  [Mar, if, you, have, an, iOS, device, you, sho...  \n",
       "3  [my, phone, does, not, run, on, latest, IOS, w...  \n",
       "4  [Not, sure, how, to, start, your, publication,...  \n",
       "5  [Two, Dollar, Tuesday, is, here, with, Forklif...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_TokenStem(data)\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.processed_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the wordlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 3744), ('to', 2477), ('i', 1667), ('a', 1620), ('on', 1557)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Counter()\n",
    "for idx in data.processed_data.index:\n",
    "    words.update(data.processed_data.loc[idx, \"text\"])\n",
    "\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most commont words (as expected) are the typical english stopwords. We will filter them out, however, as purpose of this analysis is to determine sentiment, words like \"not\" and \"n't\" can influence it greatly. Having this in mind, this word will be whitelisted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('may', 1027), ('tomorrow', 764), ('day', 526), ('go', 499), ('thi', 495)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "whitelist = [\"n't\", \"not\"]\n",
    "for idx, stop_word in enumerate(stopwords):\n",
    "    if stop_word not in whitelist:\n",
    "        del words[stop_word]\n",
    "words.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, there are some words that seem too be occuring to many times, i  filter them. After some analysis, the lower bound was set to 3.\n",
    "\n",
    "The wordlist is also saved to the csv file, so the same words can be used for the testing set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_Wordlist(TwitterData_TokenStem):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        \n",
    "    whitelist = [\"n't\",\"not\"]\n",
    "    wordlist = []\n",
    "        \n",
    "    def build_wordlist(self, min_occurrences=3, max_occurences=500, stopwords=nltk.corpus.stopwords.words(\"english\"),\n",
    "                       whitelist=None):\n",
    "        self.wordlist = []\n",
    "        whitelist = self.whitelist if whitelist is None else whitelist\n",
    "        import os\n",
    "        if os.path.isfile(\"data\\\\wordlist.csv\"):\n",
    "            word_df = pd.read_csv(\"data\\\\wordlist.csv\")\n",
    "            word_df = word_df[word_df[\"occurrences\"] > min_occurrences]\n",
    "            self.wordlist = list(word_df.loc[:, \"word\"])\n",
    "            return\n",
    "\n",
    "        words = Counter()\n",
    "        for idx in self.processed_data.index:\n",
    "            words.update(self.processed_data.loc[idx, \"text\"])\n",
    "\n",
    "        for idx, stop_word in enumerate(stopwords):\n",
    "            if stop_word not in whitelist:\n",
    "                del words[stop_word]\n",
    "\n",
    "        word_df = pd.DataFrame(data={\"word\": [k for k, v in words.most_common() if min_occurrences < v < max_occurences],\n",
    "                                     \"occurrences\": [v for k, v in words.most_common() if min_occurrences < v < max_occurences]},\n",
    "                               columns=[\"word\", \"occurrences\"])\n",
    "\n",
    "        word_df.to_csv(\"data\\\\wordlist.csv\", index_label=\"idx\")\n",
    "        self.wordlist = [k for k, v in words.most_common() if min_occurrences < v < max_occurences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = TwitterData_Wordlist(data)\n",
    "data.build_wordlist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"4afcf35c-7247-4461-bced-89ea05aa91ac\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"4afcf35c-7247-4461-bced-89ea05aa91ac\", [{\"orientation\": \"h\", \"type\": \"bar\", \"y\": [\"watch\", \"amp\", \"like\", \"get\", \"time\", \"see\", \"im\", \"not\", \"wa\", \"thi\", \"go\"], \"x\": [285, 301, 344, 348, 359, 372, 374, 426, 483, 495, 499]}], {\"title\": \"Top words in built wordlist\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = pd.read_csv(\"data\\\\wordlist.csv\")\n",
    "x_words = list(words.loc[0:10,\"word\"])\n",
    "x_words.reverse()\n",
    "y_occ = list(words.loc[0:10,\"occurrences\"])\n",
    "y_occ.reverse()\n",
    "\n",
    "dist = [\n",
    "    graph_objs.Bar(\n",
    "        x=y_occ,\n",
    "        y=x_words,\n",
    "        orientation=\"h\"\n",
    ")]\n",
    "plotly.offline.iplot({\"data\":dist, \"layout\":graph_objs.Layout(title=\"Top words in built wordlist\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words\n",
    "The data is ready to transform it to bag-of-words representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TwitterData_BagOfWords(TwitterData_Wordlist):\n",
    "    def __init__(self, previous):\n",
    "        self.processed_data = previous.processed_data\n",
    "        self.wordlist = previous.wordlist\n",
    "    \n",
    "    def build_data_model(self):\n",
    "        label_column = []\n",
    "        if not self.is_testing:\n",
    "            label_column = [\"label\"]\n",
    "\n",
    "        columns = label_column + list(\n",
    "            map(lambda w: w + \"_bow\",self.wordlist))\n",
    "        labels = []\n",
    "        rows = []\n",
    "        for idx in self.processed_data.index:\n",
    "            current_row = []\n",
    "\n",
    "            if not self.is_testing:\n",
    "                # add label\n",
    "                current_label = self.processed_data.loc[idx, \"emotion\"]\n",
    "                labels.append(current_label)\n",
    "                current_row.append(current_label)\n",
    "\n",
    "            # add bag-of-words\n",
    "            tokens = set(self.processed_data.loc[idx, \"text\"])\n",
    "            for _, word in enumerate(self.wordlist):\n",
    "                current_row.append(1 if word in tokens else 0)\n",
    "\n",
    "            rows.append(current_row)\n",
    "\n",
    "        self.data_model = pd.DataFrame(rows, columns=columns)\n",
    "        self.data_labels = pd.Series(labels)\n",
    "        return self.data_model, self.data_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>go_bow</th>\n",
       "      <th>thi_bow</th>\n",
       "      <th>wa_bow</th>\n",
       "      <th>not_bow</th>\n",
       "      <th>im_bow</th>\n",
       "      <th>see_bow</th>\n",
       "      <th>time_bow</th>\n",
       "      <th>get_bow</th>\n",
       "      <th>like_bow</th>\n",
       "      <th>...</th>\n",
       "      <th>topless_bow</th>\n",
       "      <th>flop_bow</th>\n",
       "      <th>scari_bow</th>\n",
       "      <th>attract_bow</th>\n",
       "      <th>pr_bow</th>\n",
       "      <th>sne_bow</th>\n",
       "      <th>harder_bow</th>\n",
       "      <th>sole_bow</th>\n",
       "      <th>rafe_bow</th>\n",
       "      <th>nc_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2185 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  go_bow  thi_bow  wa_bow  not_bow  im_bow  see_bow  time_bow  \\\n",
       "0   neutral       0        0       0        0       0        0         0   \n",
       "1   neutral       0        0       0        0       0        0         0   \n",
       "2  negative       0        0       1        1       0        0         1   \n",
       "3  positive       0        0       0        1       0        0         0   \n",
       "4   neutral       0        0       0        0       0        0         0   \n",
       "\n",
       "   get_bow  like_bow   ...    topless_bow  flop_bow  scari_bow  attract_bow  \\\n",
       "0        0         0   ...              0         0          0            0   \n",
       "1        0         0   ...              0         0          0            0   \n",
       "2        0         0   ...              0         0          0            0   \n",
       "3        0         0   ...              0         0          0            0   \n",
       "4        0         0   ...              0         0          0            0   \n",
       "\n",
       "   pr_bow  sne_bow  harder_bow  sole_bow  rafe_bow  nc_bow  \n",
       "0       0        0           0         0         0       0  \n",
       "1       0        0           0         0         0       0  \n",
       "2       0        0           0         0         0       0  \n",
       "3       0        0           0         0         0       0  \n",
       "4       0        0           0         0         0       0  \n",
       "\n",
       "[5 rows x 2185 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_BagOfWords(data)\n",
    "bow, labels = data.build_data_model()\n",
    "bow.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"617a56ce-134c-48c9-9949-622c9136dfa4\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"617a56ce-134c-48c9-9949-622c9136dfa4\", [{\"type\": \"bar\", \"name\": \"positive\", \"y\": [254, 247, 244, 210, 187, 182, 169, 136, 127, 28, 30, 55, 161], \"x\": [\"thi\", \"go\", \"see\", \"im\", \"wa\", \"time\", \"friday\", \"not\", \"like\", \"trump\", \"plan\", \"obama\", \"get\"]}, {\"type\": \"bar\", \"name\": \"negative\", \"y\": [80, 51, 37, 46, 89, 46, 17, 103, 72, 61, 60, 57, 54], \"x\": [\"thi\", \"go\", \"see\", \"im\", \"wa\", \"time\", \"friday\", \"not\", \"like\", \"trump\", \"plan\", \"obama\", \"get\"]}, {\"type\": \"bar\", \"name\": \"neutral\", \"y\": [145, 153, 78, 89, 156, 113, 81, 169, 131, 74, 48, 77, 118], \"x\": [\"thi\", \"go\", \"see\", \"im\", \"wa\", \"time\", \"friday\", \"not\", \"like\", \"trump\", \"plan\", \"obama\", \"get\"]}], {\"title\": \"Most common words across sentiments\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = bow.groupby([\"label\"]).sum()\n",
    "words_to_visualize = []\n",
    "sentiments = [\"positive\",\"negative\",\"neutral\"]\n",
    "#get the most 7 common words for every sentiment\n",
    "for sentiment in sentiments:\n",
    "    words = grouped.loc[sentiment,:]\n",
    "    words.sort_values(inplace=True,ascending=False)\n",
    "    for w in words.index[:7]:\n",
    "        if w not in words_to_visualize:\n",
    "            words_to_visualize.append(w)\n",
    "            \n",
    "            \n",
    "#visualize it\n",
    "plot_data = []\n",
    "for sentiment in sentiments:\n",
    "    plot_data.append(graph_objs.Bar(\n",
    "            x = [w.split(\"_\")[0] for w in words_to_visualize],\n",
    "            y = [grouped.loc[sentiment,w] for w in words_to_visualize],\n",
    "            name = sentiment\n",
    "    ))\n",
    "    \n",
    "plotly.offline.iplot({\n",
    "        \"data\":plot_data,\n",
    "        \"layout\":graph_objs.Layout(title=\"Most common words across sentiments\")\n",
    "    })\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following utility function will train the classifier and show the F1, precision, recall and accuracy scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(X_train, y_train, X_test, y_test, classifier):\n",
    "    log(\"\")\n",
    "    log(\"===============================================\")\n",
    "    classifier_name = str(type(classifier).__name__)\n",
    "    log(\"Testing \" + classifier_name)\n",
    "    now = time()\n",
    "    list_of_labels = sorted(list(set(y_train)))\n",
    "    model = classifier.fit(X_train, y_train)\n",
    "    log(\"Learing time {0}s\".format(time() - now))\n",
    "    now = time()\n",
    "    predictions = model.predict(X_test)\n",
    "    log(\"Predicting time {0}s\".format(time() - now))\n",
    "\n",
    "    precision = precision_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    recall = recall_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions, average=None, pos_label=None, labels=list_of_labels)\n",
    "    log(\"=================== Results ===================\")\n",
    "    log(\"            Negative     Neutral     Positive\")\n",
    "    log(\"F1       \" + str(f1))\n",
    "    log(\"Precision\" + str(precision))\n",
    "    log(\"Recall   \" + str(recall))\n",
    "    log(\"Accuracy \" + str(accuracy))\n",
    "    log(\"===============================================\")\n",
    "\n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "def log(x):\n",
    "    #can be used to write to log file\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: BOW + Naive Bayes\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here i used \"8 fold validation\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Crossvalidating BernoulliNB...\n",
      "Crosvalidation completed in 4.4375975131988525s\n",
      "Accuracy: [ 0.54639175  0.48820059  0.28023599  0.31415929  0.32743363  0.50073855\n",
      "  0.47119645  0.53106509]\n",
      "Average accuracy: 0.432427668406\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "nb_acc = cv(BernoulliNB(), bow.iloc[:,1:], bow.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3443: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>number_of_uppercase</th>\n",
       "      <th>number_of_exclamation</th>\n",
       "      <th>number_of_question</th>\n",
       "      <th>number_of_ellipsis</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_positive_emo</th>\n",
       "      <th>...</th>\n",
       "      <th>topless_bow</th>\n",
       "      <th>flop_bow</th>\n",
       "      <th>scari_bow</th>\n",
       "      <th>attract_bow</th>\n",
       "      <th>pr_bow</th>\n",
       "      <th>sne_bow</th>\n",
       "      <th>harder_bow</th>\n",
       "      <th>sole_bow</th>\n",
       "      <th>rafe_bow</th>\n",
       "      <th>nc_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  number_of_uppercase  number_of_exclamation  number_of_question  \\\n",
       "0   neutral                    2                      0                   0   \n",
       "1   neutral                    0                      0                   0   \n",
       "2  negative                    2                      0                   0   \n",
       "3  positive                    0                      0                   1   \n",
       "4   neutral                    4                      0                   0   \n",
       "\n",
       "   number_of_ellipsis  number_of_hashtags  number_of_mentions  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   1   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   number_of_quotes  number_of_urls  number_of_positive_emo   ...    \\\n",
       "0                 0               1                       0   ...     \n",
       "1                 0               1                       0   ...     \n",
       "2                 0               0                       0   ...     \n",
       "3                 0               1                       0   ...     \n",
       "4                 0               1                       0   ...     \n",
       "\n",
       "   topless_bow  flop_bow  scari_bow  attract_bow  pr_bow  sne_bow  harder_bow  \\\n",
       "0            0         0          0            0       0        0           0   \n",
       "1            0         0          0            0       0        0           0   \n",
       "2            0         0          0            0       0        0           0   \n",
       "3            0         0          0            0       0        0           0   \n",
       "4            0         0          0            0       0        0           0   \n",
       "\n",
       "   sole_bow  rafe_bow  nc_bow  \n",
       "0         0         0       0  \n",
       "1         0         0       0  \n",
       "2         0         0       0  \n",
       "3         0         0       0  \n",
       "4         0         0       0  \n",
       "\n",
       "[5 rows x 2195 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TwitterData_ExtraFeatures()\n",
    "data.initialize(\"data\\\\train.csv\")\n",
    "data.build_features()\n",
    "data.cleanup(TwitterCleanuper())\n",
    "data.tokenize()\n",
    "data.stem()\n",
    "data.build_wordlist()\n",
    "data_model, labels = data.build_data_model()\n",
    "data_model.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: extended features + Random Forest\n",
    "As a second attempt on the classification the i used **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===============================================\n",
      "Testing RandomForestClassifier\n",
      "Learing time 6.9144287109375s\n",
      "Predicting time 0.21802711486816406s\n",
      "=================== Results ===================\n",
      "            Negative     Neutral     Positive\n",
      "F1       [ 0.24501425  0.47944007  0.70340909]\n",
      "Precision[ 0.47777778  0.49192101  0.63163265]\n",
      "Recall   [ 0.16475096  0.46757679  0.79358974]\n",
      "Accuracy 0.575291948371\n",
      "===============================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_model.iloc[:, 1:], data_model.iloc[:, 0],\n",
    "                                                    train_size=0.7, stratify=data_model.iloc[:, 0],\n",
    "                                                    random_state=seed)\n",
    "precision, recall, accuracy, f1 = test_classifier(X_train, y_train, X_test, y_test, RandomForestClassifier(random_state=seed,n_estimators=403,n_jobs=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It looks better, however it's still not much above accuracy of the random classifier and barely better than Naive Bayes classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>number_of_uppercase</th>\n",
       "      <th>number_of_exclamation</th>\n",
       "      <th>number_of_question</th>\n",
       "      <th>number_of_ellipsis</th>\n",
       "      <th>number_of_hashtags</th>\n",
       "      <th>number_of_mentions</th>\n",
       "      <th>number_of_quotes</th>\n",
       "      <th>number_of_urls</th>\n",
       "      <th>number_of_positive_emo</th>\n",
       "      <th>...</th>\n",
       "      <th>topless_bow</th>\n",
       "      <th>flop_bow</th>\n",
       "      <th>scari_bow</th>\n",
       "      <th>attract_bow</th>\n",
       "      <th>pr_bow</th>\n",
       "      <th>sne_bow</th>\n",
       "      <th>harder_bow</th>\n",
       "      <th>sole_bow</th>\n",
       "      <th>rafe_bow</th>\n",
       "      <th>nc_bow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>628949369883000832</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>628976607420645377</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>629023169169518592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>629179223232479232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>629186282179153920</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2398 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          original_id  number_of_uppercase  number_of_exclamation  \\\n",
       "0  628949369883000832                    0                      0   \n",
       "1  628976607420645377                    1                      1   \n",
       "2  629023169169518592                    0                      0   \n",
       "3  629179223232479232                    0                      0   \n",
       "4  629186282179153920                    1                      0   \n",
       "\n",
       "   number_of_question  number_of_ellipsis  number_of_hashtags  \\\n",
       "0                   1                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   1                   0                   2   \n",
       "\n",
       "   number_of_mentions  number_of_quotes  number_of_urls  \\\n",
       "0                   1                 0               0   \n",
       "1                   1                 0               0   \n",
       "2                   0                 0               0   \n",
       "3                   0                 0               0   \n",
       "4                   2                 0               0   \n",
       "\n",
       "   number_of_positive_emo   ...    topless_bow  flop_bow  scari_bow  \\\n",
       "0                       0   ...              0         0          0   \n",
       "1                       0   ...              0         0          0   \n",
       "2                       0   ...              0         0          0   \n",
       "3                       0   ...              0         0          0   \n",
       "4                       0   ...              0         0          0   \n",
       "\n",
       "   attract_bow  pr_bow  sne_bow  harder_bow  sole_bow  rafe_bow  nc_bow  \n",
       "0            0       0        0           0         0         0       0  \n",
       "1            0       0        0           0         0         0       0  \n",
       "2            0       0        0           0         0         0       0  \n",
       "3            0       0        0           0         0         0       0  \n",
       "4            0       0        0           0         0         0       0  \n",
       "\n",
       "[5 rows x 2398 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TwitterData()\n",
    "test_data.initialize(\"kaggletest.csv\", is_testing_set=True)\n",
    "test_data.build_features()\n",
    "test_data.cleanup(TwitterCleanuper())\n",
    "test_data.tokenize()\n",
    "test_data.stem()\n",
    "test_data.build_wordlist()\n",
    "test_data.data_model.head(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
